# TP 4 ‚Äì Reporting et Monitoring avec Allure, Prometheus et Grafana

## üéØ Objectifs p√©dagogiques

√Ä l'issue de ce TP, vous serez capable de :

1. **G√©n√©rer des rapports HTML de tests** avec Allure
2. **Exporter des m√©triques de tests** vers Prometheus
3. **Visualiser les m√©triques** dans des dashboards Grafana
4. **Automatiser** la publication des rapports dans un pipeline CI/CD
5. **Monitorer** l'√©volution des tests dans le temps

## üîß Pr√©-requis logiciels

### Logiciels requis
- **Python 3.11+** ([python.org](https://python.org))
- **Git** ([git-scm.com](https://git-scm.com))
- **Docker** et **Docker Compose** ([docker.com](https://docker.com)) - **REQUIS**
- **Node.js** et **npm** (pour Allure CLI) - **REQUIS**
  ```bash
  # V√©rifier Node.js
  node --version  # Doit √™tre >= 16
  npm --version
  ```

---

## √âtape 1 ‚Äì Configuration du projet et installation d'Allure

### üéØ Objectif
Initialiser le projet et configurer Allure pour g√©n√©rer des rapports HTML de tests.

**Ce que vous allez faire :**
- Cr√©er la structure du projet avec des tests pytest
- Installer Allure CLI via npm
- Configurer pytest pour exporter les r√©sultats vers Allure
- G√©n√©rer votre premier rapport HTML Allure

**Pourquoi :** Allure est un outil standard dans l'industrie pour g√©n√©rer des rapports de tests professionnels et visuellement attrayants.

### üß© Instructions

#### 1.1 clone le projet et creation de votre branche :

```bash
git checkout -b <votre_nom_prenom>
```

#### 1.2 Structure des dossiers

```
tp2-allure-monitoring/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ calculator.py          # Application simple
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_calculator.py     # Tests √† ex√©cuter
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py            # Configuration pytest + Allure
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îî‚îÄ‚îÄ prometheus_exporter.py # Exporteur Prometheus
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ export_metrics.sh      # Script d'automatisation
‚îú‚îÄ‚îÄ reports/                    # R√©sultats Allure (JSON)
‚îú‚îÄ‚îÄ allure-report/              # Rapport HTML g√©n√©r√©
‚îú‚îÄ‚îÄ prometheus/                 # Configuration Prometheus
‚îÇ   ‚îî‚îÄ‚îÄ prometheus.yml
‚îú‚îÄ‚îÄ grafana/                    # Configuration Grafana
‚îÇ   ‚îî‚îÄ‚îÄ datasources/
‚îÇ       ‚îî‚îÄ‚îÄ prometheus.yml
‚îú‚îÄ‚îÄ docker-compose.yml          # Stack Docker
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ pytest.ini
‚îú‚îÄ‚îÄ conftest.py                 # Configuration globale
‚îî‚îÄ‚îÄ .gitignore
```

#### 1.3 Installation d'Allure CLI

**Sur macOS/Linux :**
```bash
npm install -g allure-commandline
allure --version
```

**Sur Windows :**
```bash
# Via Chocolatey
choco install allure-commandline

# Ou via Scoop
scoop install allure
```

#### 1.4 Cr√©er les fichiers de base

**`requirements.txt` :**
```txt
pytest==7.4.3
allure-pytest==2.13.2
prometheus-client==0.19.0
requests==2.31.0
```

**`pytest.ini` :**
```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    -v
    --alluredir=reports
    --tb=short
```

**`conftest.py` (√† la racine) :**
```python
"""Configuration pytest et Allure"""
import sys
from pathlib import Path

# Ajouter src au PYTHONPATH
root_dir = Path(__file__).parent
sys.path.insert(0, str(root_dir))
```

#### 1.5 Application et les tests

Les fichiers suivants sont d√©ja presents dans le projet :

**`src/calculator.py` :**

**`tests/test_calculator.py` :**

**`tests/test_calculator_advanced.py` :**

**`tests/test_calculator_integration.py` :**

**`tests/test_calculator_stress.py` :**

** Les fichiers de tests cr√©ent intentionnellement des tests qui √©chouent pour d√©montrer :
- Les rapports Allure avec √©checs
- Les m√©triques Prometheus avec diff√©rents statuts
- Les dashboards Grafana avec des tendances vari√©es
- Des dur√©es de tests diff√©rentes (rapides vs lents)
- Diff√©rentes s√©v√©rit√©s de tests

**R√©sum√© des tests cr√©√©s :**
- **Total : 41 tests**
- **R√©ussis : 36 tests** (88%)
- **√âchouent : 5 tests** (12%) - tests intentionnellement en √©chec pour d√©monstration
- **Dur√©es vari√©es :** tests rapides (< 100ms) et lents (> 500ms)
- **S√©v√©rit√©s Allure :** CRITICAL, NORMAL, MINOR, BLOCKER, TRIVIAL
- **4 suites de tests :** Basic, Advanced, Integration, Stress

#### 1.6 Execution des tests

Installer les d√©pendances

```bash
# Installer les d√©pendances
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

Ex√©cuter les tests

```bash

# Ex√©cuter TOUS les tests (environ 40 tests avec succ√®s et √©checs)
pytest tests/ -v

# Ex√©cuter une suite sp√©cifique
pytest tests/test_calculator.py -v           # Suite 1: Tests de base
pytest tests/test_calculator_advanced.py -v  # Suite 2: Tests avanc√©s
pytest tests/test_calculator_integration.py -v  # Suite 3: Tests d'int√©gration
pytest tests/test_calculator_stress.py -v    # Suite 4: Tests de stress

# Ex√©cuter uniquement les tests qui √©chouent (pour voir les erreurs)
pytest tests/ -v --lf

# Ex√©cuter avec statistiques d√©taill√©es
pytest tests/ -v --tb=short
```

G√©n√©rer le rapport Allure HTML (avec tous les tests)

```bash
# G√©n√©rer le rapport Allure HTML (avec tous les tests)
pytest tests/ -v --alluredir=reports
allure generate reports --clean -o allure-report
```

# Ouvrir le rapport

```bash
# Ouvrir le rapport
allure open allure-report
```

### üß™ R√©sultat attendu

‚úÖ 41 tests ex√©cut√©s (36 r√©ussis, 5 √©checs intentionnels)  
‚úÖ Fichiers JSON Allure g√©n√©r√©s dans `reports/` pour tous les tests  
‚úÖ Rapport HTML Allure g√©n√©r√© dans `allure-report/` avec :
- Graphiques de statistiques (succ√®s/√©checs)
- R√©partition par suite de tests (Basic, Advanced, Integration, Stress)
- R√©partition par s√©v√©rit√© (CRITICAL, NORMAL, MINOR, BLOCKER, TRIVIAL)
- Dur√©es des tests (rapides vs lents)
- D√©tails des erreurs pour les tests √©chou√©s
‚úÖ Rapport ouvert dans le navigateur avec visualisations riches

**Ce que vous verrez dans Allure :**

- **Overview** : Environ 88% de r√©ussite, 12% d'√©checs
- **Graphs** : Distribution des dur√©es, timeline des ex√©cutions
- **Suites** : 4 suites diff√©rentes avec leurs statistiques
- **Behaviors** : Groupement par stories (Addition, Division, Performance, etc.)

---

## √âtape 2 ‚Äì Configuration Prometheus avec Docker

### üéØ Objectif
Configurer Prometheus pour collecter et stocker les m√©triques de tests.

**Ce que vous allez faire :**
- Cr√©er un exporter Prometheus qui expose les m√©triques de tests
- Configurer Prometheus pour scraper ces m√©triques
- Lancer Prometheus avec Docker Compose
- Visualiser les m√©triques dans l'interface Prometheus

**Pourquoi :** Prometheus est le standard de l'industrie pour le monitoring de m√©triques temporelles, permettant de tracer l'√©volution des tests dans le temps.

### üß© Instructions

#### 2.1 Cr√©er l'exporter Prometheus

**`monitoring/prometheus_exporter.py` :**
```python
"""
Exporteur Prometheus pour les m√©triques de tests
Expose les m√©triques via un endpoint HTTP que Prometheus peut scraper
"""

from prometheus_client import Counter, Gauge, Histogram, start_http_server
import time
import json
from pathlib import Path


# M√©triques Prometheus
tests_total = Counter('tests_total', 'Total de tests ex√©cut√©s', ['status', 'suite'])
tests_duration = Histogram('tests_duration_seconds', 'Dur√©e des tests en secondes', ['suite'])
test_success_rate = Gauge('test_success_rate', 'Taux de succ√®s des tests (0-100)', ['suite'])


class PrometheusExporter:
    """Exporte les m√©triques de tests vers Prometheus"""
    
    def __init__(self, port: int = 8000):
        self.port = port
        self.metrics_file = Path('reports')
    
    def start_server(self):
        """D√©marre le serveur HTTP pour Prometheus"""
        start_http_server(self.port)
        print(f"‚úÖ Serveur Prometheus d√©marr√© sur le port {self.port}")
        print(f"üìç M√©triques disponibles: http://localhost:{self.port}/metrics")
    
    def update_metrics_from_allure(self):
        """Lit les r√©sultats Allure et met √† jour les m√©triques"""
        if not self.metrics_file.exists():
            print("‚ö†Ô∏è  Aucun r√©sultat Allure trouv√©")
            return
        
        # Compter les tests par statut
        passed = 0
        failed = 0
        broken = 0
        skipped = 0
        
        # Parser les fichiers JSON Allure
        for result_file in self.metrics_file.glob('*-result.json'):
            try:
                with open(result_file, 'r') as f:
                    data = json.load(f)
                    
                status = data.get('status', 'unknown')
                suite = 'default'  # On pourrait extraire depuis les labels
                duration = data.get('stop', 0) - data.get('start', 0)
                
                # Incr√©menter les compteurs
                if status == 'passed':
                    passed += 1
                    tests_total.labels(status='passed', suite=suite).inc()
                elif status == 'failed':
                    failed += 1
                    tests_total.labels(status='failed', suite=suite).inc()
                elif status == 'broken':
                    broken += 1
                    tests_total.labels(status='broken', suite=suite).inc()
                elif status == 'skipped':
                    skipped += 1
                    tests_total.labels(status='skipped', suite=suite).inc()
                
                # Enregistrer la dur√©e
                if duration > 0:
                    tests_duration.labels(suite=suite).observe(duration / 1000.0)  # ms -> s
                    
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur lecture {result_file}: {e}")
        
        # Calculer le taux de succ√®s
        total = passed + failed + broken
        if total > 0:
            success_rate = (passed / total) * 100
            test_success_rate.labels(suite='all').set(success_rate)
        
        print(f"üìä M√©triques mises √† jour: {passed} passed, {failed} failed, {broken} broken, {skipped} skipped")


def main():
    """Point d'entr√©e principal"""
    exporter = PrometheusExporter(port=8000)
    exporter.start_server()
    
    # Mettre √† jour les m√©triques toutes les 30 secondes
    while True:
        exporter.update_metrics_from_allure()
        time.sleep(30)


if __name__ == '__main__':
    main()
```

#### 2.2 Configuration Prometheus :

**`prometheus/prometheus.yml` :**
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'test-metrics'
    static_configs:
      - targets: ['host.docker.internal:8000']
        labels:
          environment: 'testing'
          
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
```

#### 2.3 Docker Compose


**`docker-compose.yml` :**
```yaml
version: "3.8"

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    extra_hosts:
      - "host.docker.internal:host-gateway"
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - monitoring

volumes:
  prometheus_data:
  grafana_data:

networks:
  monitoring:
    driver: bridge
```

#### 2.4 Configuration Grafana datasource

**`grafana/datasources/prometheus.yml` :**
```yaml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true
```

#### 2.5 D√©marrer Prometheus et Grafana

```bash
# MAINTENANT d√©marrer Prometheus et Grafana
docker-compose up -d

# V√©rifier que les containers sont d√©marr√©s
docker-compose ps

# V√©rifier les logs si probl√®me
docker-compose logs prometheus
docker-compose logs grafana
```

Dans un autre terminal, d√©marrer l'exporter Python

```bash
# Dans un autre terminal, d√©marrer l'exporter Python
python monitoring/prometheus_exporter.py

# Acc√©der aux interfaces
# Prometheus: http://localhost:9090
# Grafana: http://localhost:3000 (admin/admin)

# V√©rifier que Prometheus scrape les m√©triques
# Aller sur http://localhost:9090/targets
```

#### 2.4 Installer Prometheus sur Windows

√âtape 1 : T√©l√©charger Prometheus
- Aller sur : https://prometheus.io/download/
- T√©l√©charger Windows ‚Üí prometheus-*.windows-amd64.zip

√âtape 2 : D√©compresser

Exemple :
```text
C:\monitoring\prometheus\
```

√âtape 3 : Lancer Prometheus

Dans PowerShell :
```powershell
cd C:\monitoring\prometheus
.\prometheus.exe --config.file=prometheus.yml
```

Acc√®s : http://localhost:9090

#### 2.5 Installer Grafana sur Windows

√âtape 1 : T√©l√©charger Grafana
- https://grafana.com/grafana/download
- Choisir Windows (Standalone ZIP) 

üëâ Installer (.exe) est plus simple pour les √©tudiants.

√âtape 2 : D√©marrer Grafana

cd "C:\Program Files\GrafanaLabs\grafana\bin"
.\grafana-server.exe

Acc√®s : http://localhost:3000


### üß™ R√©sultat attendu

‚úÖ Prometheus et Grafana d√©marr√©s avec Docker  
‚úÖ Exporter Python accessible sur le port 8000  
‚úÖ Prometheus scrape les m√©triques de tests  
‚úÖ M√©triques visibles dans l'interface Prometheus

---

## √âtape 3 ‚Äì Cr√©ation de dashboards Grafana

### üéØ Objectif
Cr√©er des dashboards Grafana pour visualiser les m√©triques de tests.

**Ce que vous allez faire :**

- Vous connecter √† Grafana
- Cr√©er un dashboard avec des graphiques pour les m√©triques de tests
- Visualiser le taux de succ√®s, le nombre de tests, les dur√©es
- Configurer des alertes si n√©cessaire

**Pourquoi :** Les dashboards Grafana permettent de visualiser l'√©volution des tests dans le temps et d'identifier rapidement les probl√®mes.

### üß© Instructions

#### 3.1 Acc√©der √† Grafana

1. Ouvrez http://localhost:3000
2. Connectez-vous avec `admin` / `admin`
3. Changer le mot de passe si demand√© (ou skip)

### üß© Instructions

#### 3.1 Acc√©der √† Grafana

1. Ouvrez http://localhost:3000
2. Connectez-vous avec `admin` / `admin`
3. Changer le mot de passe si demand√© (ou skip)

#### 3.2 Cr√©er un dashboard

1. Cliquez sur **"Dashboards"** ‚Üí **"New"** ‚Üí **"New Dashboard"**
2. Cliquez sur **"Add visualization"**
3. S√©lectionnez la datasource **"Prometheus"**


#### 3.3 Panneaux √† cr√©er

**Panneau 1 : Taux de succ√®s des tests**
- **Query:** `test_success_rate{suite="all"}`
- **Visualization:** Stat (Gauge)
- **Title:** "Test Success Rate (%)"
- **Unit:** Percent (0-100)
- **Thresholds:**
  - Green: 90-100
  - Yellow: 70-90
  - Red: 0-70

**Panneau 2 : Nombre de tests par statut**
- **Query:** `tests_total`
- **Visualization:** Bar chart
- **Title:** "Tests by Status"
- **Legend:** `{{status}}`

**Panneau 3 : Dur√©e totale des tests**
- **Query:** `sum(tests_duration_seconds_bucket)`
- **Visualization:** Time series
- **Title:** "Total Test Duration (seconds)"

**Panneau 4 : √âvolution du taux de succ√®s dans le temps**
- **Query:** `test_success_rate{suite="all"}`
- **Visualization:** Time series
- **Title:** "Success Rate Over Time"

#### 3.4 Sauvegarder le dashboard

1. Cliquez sur **"Save dashboard"**
2. Nommez-le "Test Metrics Dashboard"
3. Sauvegardez

#### 3.5 Ex√©cuter les tests plusieurs fois pour g√©n√©rer de l'historique 

**Sur macOS/Linux :**
```bash
# D√©marrer l'exporter Prometheus en arri√®re-plan (dans un terminal)
python monitoring/prometheus_exporter.py &

# Dans un autre terminal, ex√©cuter les tests plusieurs fois
for i in {1..10}; do
  echo "=== Run $i de tests ==="
  pytest tests/ -v --alluredir=reports
  echo "Attente de 10 secondes avant le prochain run..."
  sleep 10
done

# L'exporter mettra √† jour les m√©triques toutes les 30 secondes
# Les m√©triques devraient appara√Ætre dans Grafana apr√®s quelques minutes
```

**Sur Windows (PowerShell) :**
```powershell
# Dans un terminal PowerShell, d√©marrer l'exporter en arri√®re-plan
Start-Job -ScriptBlock { python monitoring/prometheus_exporter.py }

# Dans un autre terminal PowerShell, ex√©cuter les tests plusieurs fois
for ($i = 1; $i -le 10; $i++) {
  Write-Host "=== Run $i de tests ==="
  pytest tests/ -v --alluredir=reports
  Write-Host "Attente de 10 secondes avant le prochain run..."
  Start-Sleep -Seconds 10
}

# Pour arr√™ter le job en arri√®re-plan:
# Stop-Job -Name "Job1"; Remove-Job -Name "Job1"
```

**R√©sultat attendu :**
- Apr√®s plusieurs runs, vous verrez dans Grafana :
  - Une √©volution du taux de succ√®s dans le temps (~88%)
  - Des variations dans le nombre de tests pass√©s/√©chou√©s
  - Des dur√©es de tests vari√©es (certains rapides, d'autres lents)
  - Des donn√©es historiques pour analyser les tendances

### üß™ R√©sultat attendu

‚úÖ Dashboard Grafana cr√©√© avec 4 panneaux  
‚úÖ M√©triques visibles et mises √† jour en temps r√©el  
‚úÖ Graphiques montrant l'√©volution des tests

---

## √âtape 4 ‚Äì Int√©gration CI/CD avec GitHub Actions

### üéØ Objectif
Automatiser la g√©n√©ration de rapports Allure dans le pipeline CI/CD et publier les r√©sultats automatiquement.

**Ce que vous allez faire :**
- Cr√©er un workflow GitHub Actions qui ex√©cute les tests
- G√©n√©rer automatiquement le rapport Allure HTML
- Publier le rapport comme artifact t√©l√©chargeable
- Ajouter des commentaires automatiques sur les Pull Requests

**Pourquoi :** L'automatisation CI/CD permet d'avoir des rapports √† jour √† chaque commit et de partager facilement les r√©sultats avec l'√©quipe.

### üß© Instructions

"Ce que vous allez faire" : vous allez construire un pipeline CI/CD complet √©tape par √©tape qui int√®gre Allure pour g√©n√©rer et publier automatiquement les rapports de tests. Cr√©ez le fichier `.github/workflows/ci-monitoring.yml` en suivant les instructions ci-dessous.

#### 5.1 Structure de base du workflow

**√âtape 1 : D√©finir le nom et les d√©clencheurs**

Ajoutez l'en-t√™te du workflow :
- `name:` : le nom du workflow (ex: "CI - Tests avec Allure et Monitoring")
- `on:` : quand le workflow doit s'ex√©cuter (push, pull_request, schedule)

**Indices :**
- Le workflow doit s'ex√©cuter sur les branches `main` et `develop` ou `nom_de_votre_branche`  lors d'un `push`
- Il doit aussi s'ex√©cuter sur les `pull_request` vers `main`
- (Optionnel) Ajoutez un d√©clencheur `schedule` pour une ex√©cution p√©riodique (toutes les 6 heures par exemple)

**V√©rification** : Votre structure doit ressembler √† :
```yaml
name: CI - Tests avec Allure et Monitoring

on:
  push:
    branches: [ ??? ]  # Quelles branches ?
  pull_request:
    branches: [ ??? ]  # Vers quelle branche ?
```

---

#### 5.2 D√©finir le job et l'environnement

"Ce que vous allez faire" : cr√©er le job principal avec l'environnement d'ex√©cution.

**√âtape 2 : Cr√©er le job principal**

Ajoutez la section `jobs:` avec un job nomm√© `test-and-report`.

**Indices :**
- `runs-on: ubuntu-latest` : ex√©cution sur Ubuntu
- Le nom du job peut √™tre descriptif : "Tests + Allure Report"

**V√©rification** : Vous devez avoir quelque chose comme :
```yaml
jobs:
  test-and-report:
    name: Tests + Allure Report
    runs-on: ???  # Quel OS ?
    
    steps:
      # Les √©tapes suivent ici...
```

---

#### 5.3 √âtapes de configuration de base

**√âtape 3 : Checkout et configuration Python**

"Ce que vous allez faire" : configurer l'environnement Python et installer les d√©pendances n√©cessaires.

Ajoutez les premi√®res √©tapes du workflow :

1. **Checkout du code** : utilisez `actions/checkout@v4`
2. **Setup Python** : utilisez `actions/setup-python@v4` avec :
  - `python-version: '3.11'`
  - `cache: 'pip'` (pour acc√©l√©rer les builds)
3. **Installation des d√©pendances** :
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```


**√âtape 4 : Installer Allure CLI**

"Ce que vous allez faire" : installer Allure CLI qui sera utilis√© pour g√©n√©rer les rapports HTML.

Ajoutez une √©tape pour installer Allure CLI via npm :
- Installez Node.js avec `actions/setup-node@v4` (version 18 par exemple)
- Installez Allure CLI globalement : `npm install -g allure-commandline`
- V√©rifiez l'installation : `allure --version`

---

#### 5.4 Ex√©cution des tests

**√âtape 5 : Ex√©cuter les tests avec collecte Allure**

"Ce que vous allez faire" : ex√©cuter tous les tests et collecter les r√©sultats au format Allure.

Ajoutez une √©tape pour ex√©cuter les tests :
- Commande : `pytest tests/ -v --alluredir=reports`
- Ajoutez `continue-on-error: true` pour que le workflow continue m√™me si des tests √©chouent

**Question √† r√©fl√©chir** : Pourquoi utilise-t-on `continue-on-error: true` ici ?

---

#### 5.5 G√©n√©ration des rapports Allure

**√âtape 6 : G√©n√©rer le rapport HTML**

"Ce que vous allez faire" : transformer les donn√©es JSON Allure en un rapport HTML interactif.

Ajoutez une √©tape avec `if: always()` pour g√©n√©rer le rapport Allure :
- Commande : `allure generate reports --clean -o allure-report`
- Cette √©tape s'ex√©cute m√™me si les tests √©chouent gr√¢ce √† `if: always()`

---

#### 5.6 Upload des artifacts

**√âtape 7 : Publier les rapports**

"Ce que vous allez faire" : sauvegarder les rapports comme artifacts t√©l√©chargeables depuis GitHub.

Cr√©ez deux √©tapes pour uploader les rapports (avec `if: always()`) :

1. **Upload des r√©sultats Allure (JSON)** :
  - Action : `actions/upload-artifact@v4`
  - `name: allure-results`
  - `path: reports/`
  - `retention-days: 30`

2. **Upload du rapport HTML Allure** :
  - M√™me action
  - `name: allure-html-report`
  - `path: allure-report/`
  - `retention-days: 30`

**Indice** : Consultez la [documentation upload-artifact](https://github.com/actions/upload-artifact) pour la syntaxe exacte.


#### 5.7 Apr√®s avoir cr√©√© votre workflow, validez-le :

```bash
# Pousser sur GitHub pour tester
git add .github/workflows/ci-monitoring.yml
git commit -m "feat: add CI/CD pipeline with Allure reporting"
git push
```

**V√©rification sur GitHub :**
1. Allez dans l'onglet "Actions" de votre d√©p√¥t
2. Vous devriez voir votre workflow s'ex√©cuter
3. Consultez les logs pour d√©tecter d'√©ventuelles erreurs
4. V√©rifiez que les tests s'ex√©cutent et que les rapports Allure sont g√©n√©r√©s

---

### üß™ R√©sultat attendu

‚úÖ Workflow cr√©√© avec succ√®s  
‚úÖ Syntaxe YAML valide  
‚úÖ Pipeline s'ex√©cute sur push
‚úÖ Tests ex√©cut√©s automatiquement  
‚úÖ Rapports Allure g√©n√©r√©s et upload√©s comme artifacts  
‚úÖ Rapport HTML t√©l√©chargeable depuis l'onglet Actions

---

### üÜò En cas d'erreur

**Erreur de syntaxe YAML :**
- V√©rifiez l'indentation (espaces, pas de tabs)
- V√©rifiez que chaque cl√© est correctement ferm√©e

**Allure CLI non install√© :**
- V√©rifiez que Node.js est bien install√© dans le workflow
- V√©rifiez les logs pour voir l'erreur d'installation

**Rapport Allure non g√©n√©r√© :**
- V√©rifiez que les tests ont bien √©t√© ex√©cut√©s avec `--alluredir=reports`
- V√©rifiez que le dossier `reports/` contient des fichiers JSON Allure

**Artifacts non upload√©s :**
- V√©rifiez que les chemins sont corrects (`reports/`, `allure-report/`)
- V√©rifiez que `if: always()` est bien pr√©sent

**Action non trouv√©e :**
- V√©rifiez les versions des actions (v4, v3, etc.)
- Consultez la documentation officielle de chaque action

---

#### 5.9 Cr√©er le .gitignore

**`.gitignore` :**
```
# Python
venv/
__pycache__/
*.pyc
*.pyo
*.pyd
.Python

# Allure
allure-report/
allure-results/
reports/*.json

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db
```


---

## üìö Ressources compl√©mentaires

- [Allure Documentation](https://docs.qameta.io/allure/)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [Prometheus Python Client](https://github.com/prometheus/client_python)

---

**üéâ F√©licitations! Vous avez compl√©t√© le TP2!**

Vous ma√Ætrisez maintenant:
‚úÖ La g√©n√©ration de rapports HTML avec Allure  
‚úÖ L'export de m√©triques vers Prometheus  
‚úÖ La visualisation dans Grafana  
‚úÖ L'automatisation dans CI/CD
